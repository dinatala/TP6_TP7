{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBY1Vdsp00eN"
   },
   "source": [
    "<center><h1> Série de Travaux Pratiques N° 7 - Machine Learning </h1></center>\n",
    "<center><h2> K-Nearest Neighbor and Decision Tree</h2></center>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OT_v-xSH8NW"
   },
   "source": [
    "Pour ce TP, on utilisera le **dataset IRIS**. Ce dernier est une base de données regroupant les caractéristiques de **trois espèces de fleurs d’Iris, à savoir Setosa, Versicolour et Virginica**. Chaque ligne de ce jeu de données est une observation des caractéristiques d’une fleur d’Iris. Ce dataset décrit les espèces d’Iris par quatre propriétés : longueur et largeur de sépales ainsi que longueur et largeur de pétales. La base de données comporte 150 observations (50 observations par espèce)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xIqBKf-_MK9"
   },
   "source": [
    "# **Partie I : K-Nearest Neighbor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fG-mqDhouw_G"
   },
   "source": [
    "# **Questions :**\n",
    "\n",
    "1- Importer les packages nécessaires\n",
    "\n",
    "2- Lire l'ensemble de données dans le dataframe pandas\n",
    "\n",
    "3- Afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
    "\n",
    "4- Extraire les variables d'entrée X\n",
    "\n",
    "5- Extraire les variables de sortie y\n",
    "\n",
    "6- Diviser le dataset en Train / Test\n",
    "\n",
    "7- Mise à l'échelle des fonctionnalités avec Transform()\n",
    "\n",
    "8- Définir votre modèle **KNN**\n",
    "\n",
    "9- Entraîner le modèle\n",
    "\n",
    "10- Prédiction sur l'ensemble de test\n",
    "\n",
    "11- Évaluation du modèle à l'aide de métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ab1P8GZVw4gj"
   },
   "outputs": [],
   "source": [
    "# IRIS Dataset : KNN\n",
    "\n",
    "\n",
    "# 1- Importer les packages nécessaires\n",
    "\n",
    "# 2- Lire l'ensemble de données dans le dataframe pandas\n",
    "\n",
    "# 3- Afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
    "\n",
    "# 4- Extraire les variables d'entrée X\n",
    "\n",
    "# 5- Extraire les variables de sortie y\n",
    "\n",
    "# 6- Diviser le dataset en Train / Test\n",
    "\n",
    "# 7- Mise à l'échelle des fonctionnalités avec Transform()\n",
    "\n",
    "# 8- Définir votre modèle KNN\n",
    "\n",
    "# 9- Entraîner le modèle\n",
    "\n",
    "# 10- Prédiction sur l'ensemble de test\n",
    "\n",
    "# 11- Évaluation du modèle à l'aide de métriques\n",
    "\n",
    "#12- Changer le K = {5, 10, 20, 30, 40}, que remarquez-vous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Importer les packages nécessaires\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal.length  sepal.width  petal.length  petal.width variety\n",
      "0           5.1          3.5           1.4          0.2  Setosa\n",
      "1           4.9          3.0           1.4          0.2  Setosa\n",
      "2           4.7          3.2           1.3          0.2  Setosa\n",
      "3           4.6          3.1           1.5          0.2  Setosa\n",
      "4           5.0          3.6           1.4          0.2  Setosa\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal.length    150 non-null float64\n",
      "sepal.width     150 non-null float64\n",
      "petal.length    150 non-null float64\n",
      "petal.width     150 non-null float64\n",
      "variety         150 non-null object\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    " #Lire l'ensemble de données dans le dataframe pandas\n",
    "data=pd.read_csv(\"iris.csv\")\n",
    "print(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraire les variables:\n",
    "x=data.drop(\"variety\",axis=1)\n",
    "y=data[\"variety\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deviser dataset en train(70% )et test(30%)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_normalised = scaler.fit_transform(x_train)\n",
    "X_test_normalised  = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer les chaines en entiers:\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "y_transform=LabelEncoder()\n",
    "y=y_transform.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=20, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "mymodel=KNeighborsClassifier(n_neighbors=20)\n",
    "mymodel.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction sur l'ensemble de test\n",
    "y_prediction = mymodel.predict(X_test_normalised  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy du modèle : 0.4222222222222222\n",
      "Matrice de confusion :\n",
      " [[19  0  0]\n",
      " [13  0  0]\n",
      " [13  0  0]]\n",
      "Rapport de classification :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Setosa       0.42      1.00      0.59        19\n",
      "  Versicolor       0.00      0.00      0.00        13\n",
      "   Virginica       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.42        45\n",
      "   macro avg       0.14      0.33      0.20        45\n",
      "weighted avg       0.18      0.42      0.25        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Calculer l'accuracy du modèle\n",
    "accuracy = accuracy_score(y_test,y_prediction)\n",
    "print(\"Accuracy du modèle :\", accuracy)\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_prediction)\n",
    "print(\"Matrice de confusion :\\n\", conf_matrix)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "class_report = classification_report(y_test,y_prediction)\n",
    "print(\"Rapport de classification :\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision pour k = 6 : 0.4222222222222222\n",
      "Précision pour k = 20 : 0.4222222222222222\n",
      "Précision pour k = 10 : 0.4222222222222222\n",
      "Précision pour k = 35 : 0.4222222222222222\n",
      "Précision pour k = 44 : 0.4222222222222222\n"
     ]
    }
   ],
   "source": [
    "k_values = [6, 20, 10, 35, 44]\n",
    "for k in k_values:\n",
    "    accuracy = accuracy_score(y_test, y_prediction)\n",
    "    print(\"Précision pour k =\", k, \":\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRAn-qhBwqgp"
   },
   "source": [
    "# **Partie II : Decision Trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UU1ELn91wg2R"
   },
   "source": [
    "# **Questions :**\n",
    "\n",
    "1- Importer les packages nécessaires\n",
    "\n",
    "2- Lire l'ensemble de données dans le dataframe pandas\n",
    "\n",
    "3- Afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
    "\n",
    "4- Extraire les variables d'entrée X\n",
    "\n",
    "5- Extraire les variables de sortie y\n",
    "\n",
    "6- Diviser le dataset en Train / Test\n",
    "\n",
    "7- Mise à l'échelle des fonctionnalités avec Transform()\n",
    "\n",
    "8- Définir votre modèle **Decision Tree**\n",
    "\n",
    "9- Entraîner le modèle\n",
    "\n",
    "10- Prédiction sur l'ensemble de test\n",
    "\n",
    "11- Évaluation du modèle à l'aide de métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfkJv-sMxI-c"
   },
   "outputs": [],
   "source": [
    "# IRIS Dataset : Decision Tree\n",
    "\n",
    "\n",
    "# 1- Importer les packages nécessaires\n",
    "\n",
    "# 2- Lire l'ensemble de données dans le dataframe pandas\n",
    "\n",
    "# 3- Afficher et explorer l'ensemble de données \"iris.csv\"\n",
    "\n",
    "# 4- Extraire les variables d'entrée X\n",
    "\n",
    "# 5- Extraire les variables de sortie y\n",
    "\n",
    "# 6- Diviser le dataset en Train / Test\n",
    "\n",
    "# 7- Mise à l'échelle des fonctionnalités avec Transform()\n",
    "\n",
    "# 8- Définir votre modèle KNN\n",
    "\n",
    "# 9- Entraîner le modèle\n",
    "\n",
    "# 10- Prédiction sur l'ensemble de test\n",
    "\n",
    "# 11- Évaluation du modèle à l'aide de métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Importer les packages nécessaires\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal.length    150 non-null float64\n",
      "sepal.width     150 non-null float64\n",
      "petal.length    150 non-null float64\n",
      "petal.width     150 non-null float64\n",
      "variety         150 non-null object\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('iris.csv')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectionner 'variety' comme variable dependante\n",
    "X = df.drop(columns='variety')\n",
    "y = df['variety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalisation\n",
    "scaler = StandardScaler()\n",
    "X_train2 = scaler.fit_transform(X_train)\n",
    "X_test2 = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=42, splitter='best')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Entraîner le modèle\n",
    "model_tree.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Prédiction sur l'ensemble de test\n",
    "y_prediction =model_tree.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy du modèle : 1.0\n",
      "Matrice de confusion :\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "Rapport de classification :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Setosa       1.00      1.00      1.00        10\n",
      "  Versicolor       1.00      1.00      1.00         9\n",
      "   Virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculer l'accuracy du modèle\n",
    "accuracy = accuracy_score(y_test, y_prediction)\n",
    "print(\"Accuracy du modèle :\", accuracy)\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_prediction)\n",
    "print(\"Matrice de confusion :\\n\", conf_matrix)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "class_report = classification_report(y_test,  y_prediction)\n",
    "print(\"Rapport de classification :\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
